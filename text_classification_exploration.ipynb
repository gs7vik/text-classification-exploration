{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65447ab9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3201710d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e072ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ============================\n",
    "# 1. Load the data\n",
    "# ============================\n",
    "train_df = pd.read_csv(\"dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "# ============================\n",
    "# 2. ULTRA-ADVANCED TEXT PREPROCESSING\n",
    "# ============================\n",
    "def ultra_advanced_preprocess_text(text):\n",
    "    \"\"\"Combined best preprocessing from both approaches\"\"\"\n",
    "    text = str(text).lower()\n",
    "    \n",
    "    # Handle numbers specially - they might indicate different subjects\n",
    "    text = re.sub(r'\\b\\d{4}\\b', ' YEAR ', text)  # Years (like 1961, 2007)\n",
    "    text = re.sub(r'\\b\\d+\\.\\d+\\b', ' DECIMAL ', text)  # Decimals (like 50.5)\n",
    "    text = re.sub(r'\\b\\d+\\b', ' NUM ', text)  # Other numbers\n",
    "    \n",
    "    # Remove special characters but keep some punctuation patterns that might be meaningful\n",
    "    text = re.sub(r'[^a-zA-Z\\s\\.\\!\\?]', ' ', text)\n",
    "    \n",
    "    # Clean up whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "print(\"   Applying ultra-advanced preprocessing...\")\n",
    "train_df['Text'] = train_df['Text'].apply(ultra_advanced_preprocess_text)\n",
    "test_df['Text'] = test_df['Text'].apply(ultra_advanced_preprocess_text)\n",
    "\n",
    "# ============================\n",
    "# 3. ULTRA-HIGH DIMENSION FEATURE COMBINATIONS\n",
    "# ============================\n",
    "\n",
    "# Ultra Feature Set 1: Maximum word features\n",
    "ultra_word_1 = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    max_features=300000,  # Ultra high!\n",
    "    ngram_range=(1, 3),\n",
    "    min_df=1,\n",
    "    max_df=0.95,\n",
    "    sublinear_tf=False\n",
    ")\n",
    "\n",
    "ultra_char_1 = TfidfVectorizer(\n",
    "    analyzer=\"char\",\n",
    "    max_features=100000,  # Ultra high!\n",
    "    ngram_range=(2, 7),   # Wide range\n",
    "    min_df=1\n",
    ")\n",
    "\n",
    "ultra_features_1 = FeatureUnion([\n",
    "    ('word_ultra', ultra_word_1),\n",
    "    ('char_ultra', ultra_char_1)\n",
    "])\n",
    "\n",
    "# Ultra Feature Set 2: Different configuration\n",
    "ultra_word_2 = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    max_features=250000,\n",
    "    ngram_range=(1, 4),  # Up to 4-grams\n",
    "    min_df=1,\n",
    "    max_df=0.98,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "ultra_char_2 = TfidfVectorizer(\n",
    "    analyzer=\"char\",\n",
    "    max_features=80000,\n",
    "    ngram_range=(3, 6)\n",
    ")\n",
    "\n",
    "ultra_features_2 = FeatureUnion([\n",
    "    ('word_ultra_2', ultra_word_2),\n",
    "    ('char_ultra_2', ultra_char_2)\n",
    "])\n",
    "\n",
    "# Ultra Feature Set 3: Extreme word-only features\n",
    "ultra_features_3 = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    max_features=400000,  # Extreme!\n",
    "    ngram_range=(1, 5),   # Very wide n-grams\n",
    "    min_df=1,\n",
    "    max_df=0.9,\n",
    "    sublinear_tf=True\n",
    ")\n",
    "\n",
    "# Standard Feature Set (for diversity)\n",
    "standard_features = TfidfVectorizer(\n",
    "    stop_words=\"english\",\n",
    "    max_features=70000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=2,\n",
    "    max_df=0.95\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 4. CREATE ULTRA-OPTIMIZED CLASSIFIERS\n",
    "# ============================\n",
    "\n",
    "# Ultra NB 1: Maximum dimensions with minimal smoothing\n",
    "ultra_nb_1 = Pipeline([\n",
    "    ('features', ultra_word_1),\n",
    "    ('clf', MultinomialNB(alpha=0.01))  # Very low alpha\n",
    "])\n",
    "\n",
    "# Ultra NB 2: Different config\n",
    "ultra_nb_2 = Pipeline([\n",
    "    ('features', ultra_word_2),\n",
    "    ('clf', MultinomialNB(alpha=0.02))\n",
    "])\n",
    "\n",
    "# Ultra SVM 1: Combined ultra features\n",
    "ultra_svm_1 = Pipeline([\n",
    "    ('features', ultra_features_1),\n",
    "    ('clf', LinearSVC(C=0.5, class_weight=\"balanced\", random_state=42, max_iter=3000))\n",
    "])\n",
    "\n",
    "# Ultra SVM 2: Different feature combination\n",
    "ultra_svm_2 = Pipeline([\n",
    "    ('features', ultra_features_2),\n",
    "    ('clf', LinearSVC(C=0.8, class_weight=\"balanced\", random_state=43, max_iter=3000))\n",
    "])\n",
    "\n",
    "# Ultra Logistic Regression\n",
    "ultra_lr = Pipeline([\n",
    "    ('features', ultra_features_3),\n",
    "    ('clf', LogisticRegression(C=1.0, class_weight=\"balanced\", max_iter=2000, random_state=42))\n",
    "])\n",
    "\n",
    "# Enhanced Logistic Regression 2\n",
    "ultra_lr_2 = Pipeline([\n",
    "    ('features', ultra_features_1),\n",
    "    ('clf', LogisticRegression(C=2.0, class_weight=\"balanced\", max_iter=1500, random_state=44))\n",
    "])\n",
    "\n",
    "# Ultra Random Forest (for diversity)\n",
    "ultra_rf = Pipeline([\n",
    "    ('features', standard_features),  # Use smaller features for RF\n",
    "    ('clf', RandomForestClassifier(n_estimators=300, max_depth=25, \n",
    "                                  class_weight=\"balanced\", random_state=45,\n",
    "                                  n_jobs=-1, min_samples_split=3))\n",
    "])\n",
    "\n",
    "# ============================\n",
    "# 5. CREATE MULTIPLE ENSEMBLE STRATEGIES\n",
    "# ============================\n",
    "\n",
    "print(\"Creating Multiple Advanced Ensembles...\")\n",
    "\n",
    "# Strategy 1: Stacked Ensemble (Meta-learning)\n",
    "base_estimators_stack = [\n",
    "    ('ultra_nb_1', ultra_nb_1),\n",
    "    ('ultra_nb_2', ultra_nb_2),\n",
    "    ('ultra_svm_1', ultra_svm_1),\n",
    "    ('ultra_svm_2', ultra_svm_2),\n",
    "    ('ultra_lr', ultra_lr)\n",
    "]\n",
    "\n",
    "stacked_ensemble = StackingClassifier(\n",
    "    estimators=base_estimators_stack,\n",
    "    final_estimator=LogisticRegression(C=1.0, class_weight=\"balanced\", random_state=42),\n",
    "    cv=3,  # 3-fold for meta-learning\n",
    "    n_jobs=-1,\n",
    "    passthrough=False\n",
    ")\n",
    "\n",
    "# Strategy 2: Hard Voting Ensemble\n",
    "hard_voting_ensemble = VotingClassifier(\n",
    "    estimators=[\n",
    "        ('ultra_nb_1', ultra_nb_1),\n",
    "        ('ultra_nb_2', ultra_nb_2),\n",
    "        ('ultra_svm_1', ultra_svm_1),\n",
    "        ('ultra_lr', ultra_lr),\n",
    "        ('ultra_rf', ultra_rf)\n",
    "    ],\n",
    "    voting='hard',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Strategy 3: Soft Voting Ensemble (for models that support probabilities)\n",
    "soft_voting_estimators = [\n",
    "    ('ultra_nb_1', ultra_nb_1),\n",
    "    ('ultra_nb_2', ultra_nb_2),\n",
    "    ('ultra_lr', ultra_lr),\n",
    "    ('ultra_lr_2', ultra_lr_2),\n",
    "    ('ultra_rf', ultra_rf)\n",
    "]\n",
    "\n",
    "soft_voting_ensemble = VotingClassifier(\n",
    "    estimators=soft_voting_estimators,\n",
    "    voting='soft',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ============================\n",
    "# 6. EVALUATE ALL STRATEGIES\n",
    "# ============================\n",
    "print(\"   Evaluating All Ensemble Strategies...\")\n",
    "\n",
    "cv_folds = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "strategies = {\n",
    "    'Stacked_Ensemble': stacked_ensemble,\n",
    "    'Hard_Voting': hard_voting_ensemble,\n",
    "    'Soft_Voting': soft_voting_ensemble\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in strategies.items():\n",
    "    print(f\"Evaluating {name}...\")\n",
    "    cv_scores = cross_val_score(\n",
    "        model, \n",
    "        train_df['Text'], \n",
    "        train_df['Subject'], \n",
    "        cv=cv_folds,\n",
    "        scoring='f1_macro',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    results[name] = {\n",
    "        'scores': cv_scores,\n",
    "        'mean': cv_scores.mean() * 100,\n",
    "        'std': cv_scores.std() * 100\n",
    "    }\n",
    "    print(f\"   {name}: {cv_scores.mean()*100:.4f} (+/- {cv_scores.std()*2*100:.4f})\")\n",
    "\n",
    "# ============================\n",
    "# 7. EVALUATE TOP INDIVIDUAL MODELS\n",
    "# ============================\n",
    "print(\"\\n   Evaluating Top Individual Models...\")\n",
    "\n",
    "individual_models = {\n",
    "    'Ultra_NB_1': ultra_nb_1,\n",
    "    'Ultra_NB_2': ultra_nb_2,\n",
    "    'Ultra_SVM_1': ultra_svm_1,\n",
    "    'Ultra_LR': ultra_lr\n",
    "}\n",
    "\n",
    "for name, model in individual_models.items():\n",
    "    cv_scores = cross_val_score(\n",
    "        model, \n",
    "        train_df['Text'], \n",
    "        train_df['Subject'], \n",
    "        cv=StratifiedKFold(n_splits=3, shuffle=True, random_state=42),\n",
    "        scoring='f1_macro',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    results[name] = {\n",
    "        'scores': cv_scores,\n",
    "        'mean': cv_scores.mean() * 100,\n",
    "        'std': cv_scores.std() * 100\n",
    "    }\n",
    "    print(f\"{name}: {cv_scores.mean()*100:.4f}\")\n",
    "\n",
    "# ============================\n",
    "# 8. DETERMINE BEST APPROACH AND TRAIN\n",
    "# ============================\n",
    "print(f\"\\n FINAL COMPETITION SCORE COMPARISON:\")\n",
    "best_approach = max(results, key=lambda x: results[x]['mean'])\n",
    "best_score = results[best_approach]['mean']\n",
    "\n",
    "for name, result in sorted(results.items(), key=lambda x: x[1]['mean'], reverse=True):\n",
    "    \n",
    "    print(f\"{indicator} {name}: {result['mean']:.4f} (+/- {result['std']*2:.4f})\")\n",
    "\n",
    "print(f\"\\n BEST APPROACH: {best_approach} ({best_score:.4f} points)\")\n",
    "\n",
    "# Train the best model\n",
    "if best_approach in strategies:\n",
    "    best_model = strategies[best_approach]\n",
    "elif best_approach in individual_models:\n",
    "    best_model = individual_models[best_approach]\n",
    "\n",
    "print(f\" Training {best_approach} on full training data...\")\n",
    "best_model.fit(train_df['Text'], train_df['Subject'])\n",
    "\n",
    "print(\"Predicting on test data...\")\n",
    "final_predictions = best_model.predict(test_df['Text'])\n",
    "\n",
    "# ============================\n",
    "# 9. CREATE SUBMISSION\n",
    "# ============================\n",
    "submission_filename = f\"{best_approach.lower()}_ultra_submission.csv\"\n",
    "final_submission = pd.DataFrame({\n",
    "    \"ID\": test_df[\"ID\"],\n",
    "    \"Subject\": final_predictions\n",
    "})\n",
    "final_submission.to_csv(submission_filename, index=False)\n",
    "\n",
    "print(f\"   Best model submission saved as: {submission_filename}\")\n",
    "\n",
    "# ============================\n",
    "# 10. FINAL RECOMMENDATIONS\n",
    "# ============================\n",
    "print(f\"\\nFINAL ANALYSIS:\")\n",
    "print(f\"Expected competition score: {best_score:.4f}\")\n",
    "\n",
    "\n",
    "# Additional backup submissions\n",
    "if results['Stacked_Ensemble']['mean'] >= 89.0:\n",
    "    print(\"\\nCreating backup Stacked Ensemble submission...\")\n",
    "    stacked_ensemble.fit(train_df['Text'], train_df['Subject'])\n",
    "    stacked_preds = stacked_ensemble.predict(test_df['Text'])\n",
    "    backup_submission = pd.DataFrame({\n",
    "        \"ID\": test_df[\"ID\"],\n",
    "        \"Subject\": stacked_preds\n",
    "    })\n",
    "    backup_submission.to_csv(\"backup_stacked_ensemble.csv\", index=False)\n",
    "    print(\"Backup stacked ensemble saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e024072d",
   "metadata": {},
   "source": [
    "ENHANCED PUSH: Advanced Feature Engineering + Multiple Ensembles + Stacking\n",
    "   Applying ultra-advanced preprocessing...\n",
    " Creating Multiple Advanced Ensembles...\n",
    "Evaluating All Ensemble Strategies...\n",
    "Evaluating Stacked_Ensemble...\n",
    " Stacked_Ensemble: 88.7833 (+/- 1.4206)\n",
    "Evaluating Hard_Voting...\n",
    "Hard_Voting: 87.8908 (+/- 1.3267)\n",
    "Evaluating Soft_Voting...\n",
    "Soft_Voting: 88.2930 (+/- 0.9658)\n",
    "\n",
    "Evaluating Top Individual Models...\n",
    "Ultra_NB_1: 87.2149\n",
    "Ultra_NB_2: 87.1269\n",
    "Ultra_SVM_1: 87.6898\n",
    "Ultra_LR: 84.2396\n",
    "\n",
    "FINAL COMPETITION SCORE COMPARISON:\n",
    "Stacked_Ensemble: 88.7833 (+/- 1.4206)\n",
    "Soft_Voting: 88.2930 (+/- 0.9658)\n",
    "Hard_Voting: 87.8908 (+/- 1.3267)\n",
    "Ultra_SVM_1: 87.6898 (+/- 1.2101)\n",
    "Ultra_NB_1: 87.2149 (+/- 1.4652)\n",
    "Ultra_NB_2: 87.1269 (+/- 1.3946)\n",
    " Ultra_LR: 84.2396 (+/- 0.7592)\n",
    "\n",
    "BEST APPROACH: Stacked_Ensemble (88.7833 points)\n",
    "Training Stacked_Ensemble on full training data...\n",
    " Predicting on test data...\n",
    "Best model submission saved as: stacked_ensemble_ultra_submission.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e70f227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
